#include "bin_packing_join_helper.hpp"

#include <algorithm>
#include <cassert>
#include <cerrno>
#include <fstream>
#include <string>
#include <unordered_map>
#include <utility>
#include <vector>

#include "db.hpp"
#include "enclave_u.h" // Headers for untrusted part (autogenerated by edger8r)
#include "sort_helper.hpp"
#include "time.hpp"

#ifdef MAX_HEAP_SIZE
const size_t max_heap_size = MAX_HEAP_SIZE;
#else
const size_t max_heap_size = 7E7; // 70MB
#endif
const size_t usable_heap_size = max_heap_size / 4;

int bin_packing_join(sgx_enclave_id_t eid, int db_id,
                     join_condition_t *join_cond, const std::string &csv_left,
                     const std::string &csv_right, int *out_tbl_id) {
    int rtn = 0;

    // Determine size of data blocks
    const size_t dblk_size = usable_heap_size;
    const size_t rows_per_dblk = dblk_size / MAX_ROW_SIZE;

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
    INFO("Datablock size: %lu bytes.\n", dblk_size);
    INFO("Rows per datablock: %lu rows.\n", rows_per_dblk);
#endif
    if (rows_per_dblk <= 0) {
        ERR("Usable SGX memory is smaller than one row\n");
    }
    metadata_t metadata;

    do {
#if defined(REPORT_BIN_PACKING_JOIN_STATS)
        unsigned long long start, end;
        unsigned long long cycles;
        double secs;
        start = RDTSC_START();
#endif

        int dblk_cnt = 0;

        rtn = collect_metadata(csv_left, join_cond->fields_left[0],
                               rows_per_dblk, &dblk_cnt, &metadata);
        if (rtn) {
            ERR("Failed to collect metadata\n");
            break;
        }
        int midpoint = dblk_cnt;

        rtn = collect_metadata(csv_right, join_cond->fields_right[0],
                               rows_per_dblk, &dblk_cnt, &metadata);
        if (rtn) {
            ERR("Failed to collect metadata\n");
            break;
        }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
        end = RDTSCP();

        cycles = end - start;
        secs = (cycles / cycles_per_sec);

        INFO("Collecting metadata took %llu cycles (%f sec)\n", cycles, secs);
        start = RDTSC_START();
#endif

        std::vector<bin_t> bins;
        rtn = bin_info_collection(dblk_cnt, metadata, &bins);
        if (rtn) {
            ERR("Failed to pack bin\n");
            break;
        }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
        end = RDTSC_START();

        cycles = end - start;
        secs = (cycles / cycles_per_sec);

        INFO("Bin information collection took %llu cycles (%f sec)\n", cycles,
             secs);
        start = RDTSCP();
#endif

        int num_rows_per_out_bin;
        rtn = out_bin_info_collection(bins, midpoint, &num_rows_per_out_bin);
        if (rtn) {
            ERR("Failed to collect output bin information.\n");
            break;
        }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
        end = RDTSC_START();

        cycles = end - start;
        secs = (cycles / cycles_per_sec);

        INFO("Output-bin information collection took %llu cycles (%f sec)\n",
             cycles, secs);
        start = RDTSCP();
#endif

        int rows_per_cell;
        int bin_info_tbl_id;
        rtn = bin_info_to_table(eid, db_id, bins, "join:bp:bin_info",
                                &rows_per_cell, &bin_info_tbl_id);
        if (rtn) {
            ERR("Failed to convert bins to table.\n");
            break;
        }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
        end = RDTSC_START();

        cycles = end - start;
        secs = (cycles / cycles_per_sec);

        INFO("Bin information to table took %llu cycles (%f sec)\n", cycles,
             secs);
        start = RDTSCP();
#endif

        // Perform Phase 3 and Phase 4 inside the enclave
        sgx_status_t sgx_ret = ecall_bin_pack_join(
            eid, &rtn, db_id, join_cond, out_tbl_id, num_rows_per_out_bin,
            bin_info_tbl_id, midpoint, bins.size(), rows_per_cell);
        if (sgx_ret || rtn) {
            ERR("Bin packing join error:%d (sgx ret:%d)\n", rtn, sgx_ret);
            return rtn;
        }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
        end = RDTSC_START();

        cycles = end - start;
        secs = (cycles / cycles_per_sec);

        INFO("Fill bins took %llu cycles (%f sec)\n", cycles, secs);
        start = RDTSCP();
#endif

    } while (0);

    // Clean up

    // TODO: remove this line
    *out_tbl_id = 1 << 30;
    return rtn;
}

int collect_metadata(const std::string &filename, int column,
                     const size_t rows_per_dblk, int *dblk_count,
                     metadata_t *metadata) {
    int original_dblk_cnt = *dblk_count;
    std::ifstream ifile(filename);
    int row_num = 0;
    for (std::string line; ifile; ++(*dblk_count)) {
        std::unordered_map<std::string, int> counter;
        for (int i = 0; i < rows_per_dblk && std::getline(ifile, line); ++i) {
            std::string::size_type start = 0;
            for (int i = 1; i < column; ++i) {
                start = line.find(',', start) + 1; // Assuming line[0] != ','
            }
            if (start == std::string::npos) {
                ERR("column number %d is larger than the number of elements of "
                    "%s at row %d.\n",
                    column, filename.c_str(), row_num);
                return -1;
            }
            auto end = line.find(',', start);
            if (start >= end) {
                ERR("value is empty. file: %s; column: %d; row %d.\n",
                    filename.c_str(), column, row_num);
                return -1;
            }
            counter[line.substr(start, end - start)]++;
            row_num++;
        }

        // Populate the the metadata after reading each datablock.
        for (const auto &pair : counter) {
            metadata_value_t *metadata_value = &((*metadata)[pair.first]);
            metadata_value->count += pair.second;
            metadata_value->max_cnt =
                std::max(metadata_value->max_cnt, pair.second);
            metadata_value->dblks.emplace_back(*dblk_count, pair.second);
        }
    }

    // Flush the last counter
#if defined(REPORT_BIN_PACKING_JOIN_STATS)
    INFO("%d rows read and %d datablocks of metadata collected for %s.\n",
         row_num, *dblk_count - original_dblk_cnt, filename.c_str());
#endif

    return 0;
}

// Attempt to merge `b` into `a`. Nothing happens and return false if failed.
bool mergeBins(bin_t *a, const bin_t *b, const int cell_size) {
    assert(a->size() == b->size());
    for (int i = 0; i < a->size(); ++i) {
        if ((*a)[i].first + (*b)[i].first > cell_size) {
            return false;
        }
    }

    for (int i = 0; i < a->size(); ++i) {
        (*a)[i].first += (*b)[i].first;

        std::copy((*b)[i].second.begin(), (*b)[i].second.end(),
                  std::back_inserter((*a)[i].second));
    }
    return true;
}

// Sort metadata and pack bins
int bin_info_collection(const int dblk_count, const metadata_t &metadata,
                        std::vector<bin_t> *bins) {
    const int cell_size = usable_heap_size / dblk_count / MAX_ROW_SIZE;
    if (cell_size <= 0) {
        ERR("Too many datablocks created.\n");
        return -1;
    }
    std::vector<metadata_value_t> sorted_meta;
    // TODO: can be optimized using std::move once the algo is stablized
    std::transform(metadata.cbegin(), metadata.cend(),
                   std::back_inserter(sorted_meta),
                   [](const auto &it) { return it.second; });

    // Do we really need this?
    std::sort(sorted_meta.begin(), sorted_meta.end(),
              [](const auto &a, const auto &b) {
                  return std::tie(a.max_cnt, a.count) >
                         std::tie(b.max_cnt, b.count);
              });

    std::vector<bin_t> res;
    bin_t last_bin(dblk_count);

    for (const auto &it : metadata) {
        auto &dblks = it.second.dblks;
        bin_t bin(dblk_count);
        for (const auto &pair : dblks) {
            bin[pair.first].first += pair.second;
            bin[pair.first].second.emplace_back(it.first, pair.second);
        }
        bool merged =
            std::any_of(res.begin(), res.end(), [&bin, cell_size](auto &b) {
                return mergeBins(&b, &bin, cell_size);
            });
        if (!merged) {
            res.emplace_back(std::move(bin));
        }
    }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
    INFO("%lu bins created with %d cells each bin and %d values each cell. "
         "Expect to have bin info table with %lu rows.\n",
         res.size(), dblk_count, cell_size,
         res.size() * dblk_count * cell_size);

#if defined(REPORT_BIN_PACKING_JOIN_PRINT_BIN)
    for (const bin_t &bin : res) {
        for (const auto &cell : bin) {
            printf("%3d ", cell.first);
        }
        printf("\n");
    }
#endif

#endif

    // TODO: remove this line once the algo is stable
    bins->swap(res);
    return 0;
}

int out_bin_info_collection(const std::vector<bin_t> &bins, int midpoint,
                            int *num_rows_per_out_bin) {
    if (bins.empty()) {
        ERR("Bin can't be empty");
        return -1;
    }
    *num_rows_per_out_bin = 0;

    for (const bin_t &bin : bins) {
        int sum = 0;
        std::unordered_map<std::string, int> lhs, rhs;
        for (int i = 0; i < midpoint; ++i) {
            const auto &cell = bin[i].second;
            for (const auto &value : cell) {
                lhs.emplace(value);
            }
        }
        for (int i = midpoint; i < bin.size(); ++i) {
            const auto &cell = bin[i].second;
            for (const auto &value : cell) {
                rhs.emplace(value);
            }
        }

        for (const auto &value : rhs) {
            sum += value.second * lhs[value.first];
        }
        *num_rows_per_out_bin = std::max(*num_rows_per_out_bin, sum);
    }

#if defined(REPORT_BIN_PACKING_JOIN_STATS)
    INFO("There will be %d rows in each output bin.\n", *num_rows_per_out_bin);
#endif

    if (*num_rows_per_out_bin <= 0) {
        ERR("num_rows_per_out_bin %d should be greater than 0.\n",
            *num_rows_per_out_bin);
        return -1;
    }

    return 0;
}

int bin_info_to_table(sgx_enclave_id_t eid, int db_id,
                      const std::vector<bin_t> &bins,
                      const std::string &tbl_name, int *rows_per_cell,
                      int *bin_info_tbl_id) {

    schema_t sc;
    sc.num_fields = 1;
    sc.offsets[0] = 0;
    sc.sizes[0] = 1 << 10;
    sc.types[0] = TINYTEXT;
    sc.row_data_size = 1 << 10;

    sgx_status_t sgx_ret;
    int ret;
    sgx_ret = ecall_create_table(eid, &ret, db_id, tbl_name.c_str(),
                                 tbl_name.length(), &sc, bin_info_tbl_id);
    if (sgx_ret || ret) {
        ERR("create table error:%d (sgx ret:%d)\n", ret, sgx_ret);
        return -1;
    }

    // Calculate the number of rows per cell
    *rows_per_cell = 0;
    for (const bin_t &bin : bins) {
        for (const auto &cell : bin) {
            *rows_per_cell = std::max(*rows_per_cell, cell.first);
        }
    }
    if (*rows_per_cell <= 0) {
        ERR("All cells are empty: %d.\n", *rows_per_cell);
        return -1;
    }

    row_t row;
    row.header.from = *bin_info_tbl_id;
    for (int j = 0; j < bins[0].size(); ++j) {
        for (int i = 0; i < bins.size(); ++i) {
            const auto &cell = bins[i][j].second;
            for (int k = 0; k < *rows_per_cell; ++k) {
                row.header.fake = true;
                if (k < cell.size()) {
                    row.header.fake = false;
                    strncpy((char *)&(&row)[sc.offsets[0]],
                            cell[k].first.c_str(), cell[k].first.size());
                }
                sgx_ret = ecall_insert_row_dbg(eid, &ret, db_id,
                                               *bin_info_tbl_id, &row);
                if (sgx_ret || ret) {
                    ERR("insert row error:%d (sgx ret:%d)\n", ret, sgx_ret);
                    return -1;
                }
            }
        }
    }

    // ecall_print_table_dbg(eid, &ret, db_id, *bin_info_tbl_id, 0, 100);

    return ret;
}
